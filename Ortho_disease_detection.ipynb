{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gO4dk3lxaWW6"
      },
      "outputs": [],
      "source": [
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Lambda, MaxPool2D, BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from keras.utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import models, layers, optimizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.utils import class_weight\n",
        "from keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta, RMSprop\n",
        "from keras.models import Sequential, model_from_json\n",
        "from keras.layers import Activation,Dense, Dropout, Flatten, Conv2D, MaxPool2D,MaxPooling2D,AveragePooling2D, BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "from keras.layers.merge import concatenate\n",
        "from keras import backend as K\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "import os\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.gridspec as gridspec\n",
        "import seaborn as sns\n",
        "import zlib\n",
        "import itertools\n",
        "import sklearn\n",
        "import itertools\n",
        "import scipy\n",
        "import skimage\n",
        "from skimage.transform import resize\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split, learning_curve,KFold,cross_val_score,StratifiedKFold\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#ROC Curve\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
        "from scipy import interp\n",
        "from itertools import cycle\n",
        "from sklearn.metrics import roc_curve, auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnp--xu2y1c1"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "class MetricsCheckpoint(Callback):\n",
        "    def __init__(self, savepath):\n",
        "        super(MetricsCheckpoint, self).__init__()\n",
        "        self.savepath = savepath\n",
        "        self.history = {}\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "        np.save(self.savepath, self.history)\n",
        "\n",
        "def plotKerasLearningCurve():\n",
        "    plt.figure(figsize=(10,5))\n",
        "    metrics = np.load('logs.npy')[()]\n",
        "    filt = ['acc'] # try to add 'loss' to see the loss learning curve\n",
        "    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n",
        "        l = np.array(metrics[k])\n",
        "        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n",
        "        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n",
        "        y = l[x]\n",
        "        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n",
        "        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n",
        "    plt.legend(loc=4)\n",
        "    plt.axis([0, None, None, None]);\n",
        "    plt.grid()\n",
        "    plt.xlabel('Number of epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize = (8,8))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=90)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "def plot_learning_curve(history):\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.savefig('./accuracy_curve.png')\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.savefig('./loss_curve.png')\n",
        "\n",
        "#ROC Curve\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
        "from scipy import interp\n",
        "from itertools import cycle\n",
        "from sklearn.metrics import roc_curve, auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtnApBYlzP-p"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Defining Hyperparameters and model structure\n",
        "image_size=224\n",
        "target_dims = (image_size,image_size,3) # add channel for RGB\n",
        "number_classes = 2\n",
        "number_epoch=150\n",
        "batch_size=16\n",
        "learningRate=0.0001\n",
        "patience=100\n",
        "# optimizer = keras.optimizers.Adam(lr=0.001)\n",
        "optimizer = keras.optimizers.RMSprop(lr=learningRate)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STEbd99kbBZY"
      },
      "outputs": [],
      "source": [
        "# create data map  (you can skip data map generation if you have already had array data . Then, they we'll be loaded in the following))\n",
        "\n",
        "dir_Frontal = \"/content/drive/My Drive/HRV-workplace/HRV_d/Ankle_fx/Categorized/Frontal/\"\n",
        "dir_Lateral = \"/content/drive/My Drive/HRV-workplace/HRV_d/Ankle_fx/Categorized/Lateral/\"\n",
        "dir_Oblique = \"/content/drive/My Drive/HRV-workplace/HRV_d/Ankle_fx/Categorized/Oblique/\"\n",
        "\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "def get_data(folder):\n",
        "    \"\"\"\n",
        "    Load the data and labels from the given folder.\n",
        "    \"\"\"\n",
        "    X = []\n",
        "    y = []\n",
        "    for folderName in os.listdir(folder):\n",
        "        if not folderName.startswith('.'):\n",
        "            if folderName in ['Patient']:\n",
        "                label = 0\n",
        "            elif folderName in ['Normal']:\n",
        "                label = 1\n",
        "\n",
        "\n",
        "\n",
        "            for image_filename in tqdm(os.listdir(folder + folderName)):\n",
        "\n",
        "                img_file = cv2.imread(folder + folderName + '/' + image_filename)\n",
        "                if img_file is not None:\n",
        "                    img_file = skimage.transform.resize(img_file, (image_size, image_size))\n",
        "                    #repeate grayscale image to create RGB- style shpae(*,*,3)\n",
        "                    img_file=img_file/224.0####################################################################change it by imagesize.0\n",
        "                    # img_file=np.dstack([img_file] * 3)\n",
        "                    img_arr = np.asarray(img_file)\n",
        "                    X.append(img_arr)\n",
        "                    y.append(label)\n",
        "    X = np.asarray(X)\n",
        "    y = np.asarray(y)\n",
        "    return X,y\n",
        "X_Frontal, Y_Frontal = get_data(dir_Frontal) \n",
        "X_Lateral, Y_Lateral = get_data(dir_Lateral) \n",
        "X_Oblique, Y_Oblique = get_data(dir_Oblique) \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5NVVg34iG-5"
      },
      "outputs": [],
      "source": [
        "# # # save data in array foramt\n",
        "\n",
        "\n",
        "# np.save('/content/drive/My Drive/HRV-workplace/HRV_d/Ankle_fx/Vector/X_Frontal', X_Frontal)\n",
        "# np.save('/content/drive/My Drive/HRV-workplace/HRV_d/Ankle_fx/Vector/X_Lateral', X_Lateral)\n",
        "# np.save('/content/drive/My Drive/HRV-workplace/HRV_d/Ankle_fx/Vector/X_Oblique', X_Oblique)\n",
        "\n",
        "\n",
        "# np.save('/content/drive/My Drive/HRV-workplace/HRV_d/Ankle_fx/Vector/Y_Frontal', Y_Frontal)\n",
        "# # or\n",
        "# np.savetxt('/content/drive/My Drive/HRV-workplace/HRV_d/Ankle_fx/Vector/Y_Frontal.txt', Y_Frontal, fmt='%d')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "# # load data in array format (you can skip data map generation if you have already had array data)\n",
        "\n",
        "X_Frontal=np.load('/content/drive/My Drive/HRV-workplace/HRV_d/Ankle_fx/Vector/X_Frontal.npy')\n",
        "X_Lateral=np.load('/content/drive/My Drive/HRV-workplace/HRV_d/Ankle_fx/Vector/X_Lateral.npy')\n",
        "X_Oblique=np.load('/content/drive/My Drive/HRV-workplace/HRV_d/Ankle_fx/Vector/X_Oblique.npy')\n",
        "\n",
        "\n",
        "Y_Frontal=np.load('/content/drive/My Drive/HRV-workplace/HRV_d/Ankle_fx/Vector/Y_Frontal.npy')\n",
        "# or\n",
        "# Y_Frontal=np.loadtxt('/content/drive/My Drive/HRV-workplace/HRV_d/Series1/Vector/Y_Frontal.txt',dtype=int)\n",
        "\n",
        "# # Y_Frontal=Y\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXAEWjBjbVkm"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "labels = {0: 'Patient',  1: 'Normal'}\n",
        "# dict_characters=labels\n",
        "# import seaborn as sns\n",
        "# df = pd.DataFrame()\n",
        "# df[\"labels\"]=Y_Frontal\n",
        "# lab = df['labels']\n",
        "# dist = lab.value_counts()\n",
        "# sns.countplot(lab)\n",
        "# print(dict_characters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkG_jvyr72fR"
      },
      "outputs": [],
      "source": [
        "#Generate Model \n",
        "\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def Model_build():\n",
        "  # Importing the important libraries\n",
        "\n",
        "  def single_branch(name_modifier):#add name_modifier cause we use a single model(like InceptionV3) mutilple times. \n",
        "    \n",
        "    base_model = InceptionV3(include_top=False, weights='imagenet')\n",
        "    for layer in base_model.layers:\n",
        "      layer.trainable = True\n",
        "    \n",
        "    for layer in base_model.layers:\n",
        "      layer._name = layer.name + str(name_modifier)\n",
        "\n",
        "\n",
        "    x = base_model.output\n",
        "    \n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # x = Dense(1024, activation='relu')(x)\n",
        "\n",
        "    # predictions = Dense(number_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=x)\n",
        "    \n",
        "    # Training only top layers i.e. the layers which we have added in the end\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  Frontal_branch=single_branch('one')\n",
        "  Lateral_branch=single_branch('two')\n",
        "  Oblique_branch=single_branch('three')\n",
        "\n",
        "\n",
        "\n",
        "  # plot_model(Oblique_branch)\n",
        "\n",
        "\n",
        "  combinedInput = concatenate([Frontal_branch.output, Lateral_branch.output,Oblique_branch.output])\n",
        "\n",
        "  predictions = Dense(number_classes, activation='softmax',name='visualize_layer')(combinedInput)\n",
        "\n",
        "\n",
        "\n",
        "  model=Model(inputs=[Frontal_branch.input,Lateral_branch.input,Oblique_branch.input],outputs=predictions)\n",
        "  return model\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "# plot_model(model)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5hOAxDxwcki"
      },
      "outputs": [],
      "source": [
        "model_score=[]\n",
        "\n",
        "for i in range(10):\n",
        "\n",
        "\n",
        "  for train_index,val_index in KFold(5, shuffle=True).split(X_Frontal):\n",
        "\n",
        "    X_Frontal_train,X_Frontal_test=X_Frontal[train_index],X_Frontal[val_index]\n",
        "    X_Lateral_train,X_Lateral_test=X_Lateral[train_index],X_Lateral[val_index]\n",
        "    X_Oblique_train,X_Oblique_test=X_Oblique[train_index],X_Oblique[val_index]\n",
        "\n",
        "    y_train,y_test=Y_Frontal[train_index],Y_Frontal[val_index]\n",
        "\n",
        "    break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  for train_index,val_index in KFold(4, shuffle=True).split(X_Frontal_train):\n",
        "\n",
        "    X_Frontal_train,X_Frontal_val=X_Frontal_train[train_index],X_Frontal_train[val_index]\n",
        "    X_Lateral_train,X_Lateral_val=X_Lateral_train[train_index],X_Lateral_train[val_index]\n",
        "    X_Oblique_train,X_Oblique_val=X_Oblique_train[train_index],X_Oblique_train[val_index]\n",
        "\n",
        "    y_train,y_val=y_train[train_index],y_train[val_index]\n",
        "\n",
        "\n",
        "    break\n",
        "\n",
        "\n",
        "\n",
        "  # one-hot encoding\n",
        "  from keras.utils.np_utils import to_categorical\n",
        "  y_trainHot = to_categorical(y_train, num_classes = number_classes)\n",
        "  y_valhot = to_categorical(y_val, num_classes = number_classes)\n",
        "  y_testhot = to_categorical(y_test, num_classes = number_classes)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #     layer.trainable = True\n",
        "\n",
        "\n",
        "  model=Model_build()\n",
        "  model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "\n",
        "  # We will try to train the last stage of InceptionV3\n",
        "  filepath='/content/drive/My Drive/HRV-workplace/5-AnkleFx/Model/Ankle_fx_3sides{}.h5'.format(i)\n",
        "  checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max',save_weights_only=True)\n",
        "  callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=patience, verbose=2),checkpoint]\n",
        "  # callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=patience, verbose=2)]\n",
        "\n",
        "\n",
        "  # Training the model for 10 epochs\n",
        "  # history = model.fit(x_train,y_trainHot, epochs=number_epoch, validation_data=(x_test,y_testhot) ,verbose=1 ,callbacks = callbacks_list)\n",
        "\n",
        "\n",
        "\n",
        "  history=model.fit([X_Frontal_train, X_Lateral_train,X_Oblique_train], y_trainHot,\n",
        "  validation_data=([X_Frontal_val, X_Lateral_val,X_Oblique_val], y_valhot),\n",
        "  epochs=number_epoch, batch_size=batch_size,callbacks = callbacks_list,verbose=1)\n",
        "\n",
        "\n",
        "  model=Model_build()\n",
        "  model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "\n",
        "  model.load_weights(filepath)\n",
        "\n",
        "\n",
        "\n",
        "  print('****** Train set evaluation .....\\n ')\n",
        "  # Evaluate model on train data\n",
        "  score = model.evaluate([X_Frontal_train, X_Lateral_train,X_Oblique_train],y_trainHot, verbose=0)\n",
        "  print('\\nKeras CNN - accuracy:', score[1], '\\n')\n",
        "  y_pred = model.predict([X_Frontal_train, X_Lateral_train,X_Oblique_train])\n",
        "  confusion_mtx=confusion_matrix(y_train, np.argmax(y_pred, axis=1))\n",
        "  print('\\n', sklearn.metrics.classification_report(np.where(y_trainHot > 0)[1], np.argmax(y_pred, axis=1), target_names=list(labels.values())), sep='') \n",
        "\n",
        "\n",
        "  # plt.show()\n",
        "  # plot_confusion_matrix(confusion_mtx, classes = list(labels.values()))\n",
        "  # plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  print('****** Val set evaluation .....\\n ')\n",
        "  # Evaluate model on test data\n",
        "  scores = model.evaluate([X_Frontal_val, X_Lateral_val,X_Oblique_val],y_valhot, verbose=0)\n",
        "  print('\\nKeras CNN - accuracy:', scores[1], '\\n')\n",
        "  y_pred = model.predict([X_Frontal_val, X_Lateral_val,X_Oblique_val])\n",
        "  confusion_mtx=confusion_matrix(y_val, np.argmax(y_pred, axis=1))\n",
        "  print('\\n', sklearn.metrics.classification_report(np.where(y_valhot > 0)[1], np.argmax(y_pred, axis=1), target_names=list(labels.values())), sep='') \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  print('****** Test set evaluation .....\\n ')\n",
        "  # Evaluate model on test data\n",
        "  x_test=[X_Frontal_test, X_Lateral_test,X_Oblique_test]\n",
        "  scores = model.evaluate([X_Frontal_test, X_Lateral_test,X_Oblique_test],y_testhot, verbose=0)\n",
        "  print('\\nKeras CNN - accuracy:', scores[1], '\\n')\n",
        "  y_pred = model.predict([X_Frontal_test, X_Lateral_test,X_Oblique_test])\n",
        "  confusion_mtx=confusion_matrix(y_test, np.argmax(y_pred, axis=1))\n",
        "  print('\\n', sklearn.metrics.classification_report(np.where(y_testhot > 0)[1], np.argmax(y_pred, axis=1), target_names=list(labels.values())), sep='') \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  print('****** Detail Test set evaluation .....\\n ')\n",
        "  from sklearn.metrics import precision_recall_fscore_support,roc_curve,auc\n",
        "  detail_result=precision_recall_fscore_support(np.where(y_testhot > 0)[1], np.argmax(y_pred, axis=1))\n",
        "  Specificity=confusion_mtx[1,1]/(confusion_mtx[1,1]+confusion_mtx[1,0])\n",
        "\n",
        "\n",
        "  fpr1, tpr1, thresholds =roc_curve(y_test, y_pred[:,1])\n",
        "  auc_result=auc(fpr1, tpr1)\n",
        "\n",
        "  print(\"Precision={}\\nRecall={}\\nSpecificity{}\\nFscore={}\".format(detail_result[0][0],detail_result[1][0],Specificity,detail_result[2][0]))\n",
        "  print('auc={}'.format(auc_result))\n",
        "\n",
        "\n",
        "  plot_learning_curve(history)\n",
        "\n",
        "  plt.show()\n",
        "  plot_confusion_matrix(confusion_mtx, classes = list(labels.values()))\n",
        "  plt.show()\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  model_score.append(scores[1] * 100)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #ROC\n",
        "\n",
        "    # Binarize the output\n",
        "  y_bin = label_binarize(y_testhot, classes=[0, 1])\n",
        "  n_classes = number_classes\n",
        "  lw=number_classes\n",
        "\n",
        "  y_score=model.predict(x_test)\n",
        "\n",
        "  fpr = dict()\n",
        "  tpr = dict()\n",
        "  roc_auc = dict()\n",
        "  for i in range(n_classes):\n",
        "      fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], y_score[:, i])\n",
        "      roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "  colors = cycle(['blue', 'red', 'green'])\n",
        "\n",
        "  print(roc_auc)\n",
        "  # for i, color in zip(range(n_classes), colors):\n",
        "  plt.plot(fpr[0], tpr[0], color='red', lw=lw,\n",
        "              label='Pre-trained Inceptiov-v3 (area = {:0.2f})'\n",
        "              ''.format(roc_auc[0]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "  plt.xlim([-0.01, 1.0])\n",
        "  plt.ylim([0.0, 1.05])\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  # plt.title('Receiver operating characteristic for multi-class data')\n",
        "  plt.legend(loc=\"lower right\")\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(model_score), np.std(model_score)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKuvZkwOAEPr"
      },
      "source": [
        "**ResNet50**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMOc5H1DsFPt"
      },
      "outputs": [],
      "source": [
        "#Generare Model Resnet\n",
        "\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def Model_build_resnet():\n",
        "\n",
        "  base_model = ResNet50(include_top=False, weights='imagenet')\n",
        "  # Training only top layers i.e. the layers which we have added in the end\n",
        "  for layer in base_model.layers:\n",
        "      layer.trainable = True\n",
        "  \n",
        "  # Taking the output of the last convolution block in InceptionV3\n",
        "  x = base_model.output\n",
        "  \n",
        "  # Adding a Global Average Pooling layer\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "\n",
        "\n",
        "  # Adding a fully connected layer having 2 neurons which will\n",
        "  # give the probability of image having either dog or cat\n",
        "  predictions = Dense(2, activation='softmax')(x)\n",
        "  \n",
        "  # Model to be trained\n",
        "  model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    \n",
        "    # Training only top layers i.e. the layers which we have added in the end\n",
        "  return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rf1EBJtFAIqU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Defining Hyperparameters and model structure\n",
        "image_size=224\n",
        "target_dims = (image_size,image_size,3) # add channel for RGB\n",
        "number_classes = 2\n",
        "number_epoch=200\n",
        "batch_size=32\n",
        "learningRate=0.0001\n",
        "patience=200\n",
        "# optimizer = keras.optimizers.Adam(lr=0.001)\n",
        "optimizer = keras.optimizers.RMSprop(lr=learningRate)\n",
        "\n",
        "\n",
        "model_score=[]\n",
        "\n",
        "for i in range(10):\n",
        "\n",
        "\n",
        "  for train_index,val_index in KFold(5, shuffle=True).split(X_Frontal):\n",
        "\n",
        "    X_Frontal_train,X_Frontal_test=X_Frontal[train_index],X_Frontal[val_index]\n",
        "    X_Lateral_train,X_Lateral_test=X_Lateral[train_index],X_Lateral[val_index]\n",
        "    X_Oblique_train,X_Oblique_test=X_Oblique[train_index],X_Oblique[val_index]\n",
        "\n",
        "    y_train,y_test=Y_Frontal[train_index],Y_Frontal[val_index]\n",
        "\n",
        "    break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  for train_index,val_index in KFold(4, shuffle=True).split(X_Frontal_train):\n",
        "\n",
        "    X_Frontal_train,X_Frontal_val=X_Frontal_train[train_index],X_Frontal_train[val_index]\n",
        "    X_Lateral_train,X_Lateral_val=X_Lateral_train[train_index],X_Lateral_train[val_index]\n",
        "    X_Oblique_train,X_Oblique_val=X_Oblique_train[train_index],X_Oblique_train[val_index]\n",
        "\n",
        "    y_train,y_val=y_train[train_index],y_train[val_index]\n",
        "\n",
        "\n",
        "    break\n",
        "\n",
        "\n",
        "\n",
        "  # one-hot encoding\n",
        "  from keras.utils.np_utils import to_categorical\n",
        "  y_trainHot = to_categorical(y_train, num_classes = number_classes)\n",
        "  y_valhot = to_categorical(y_val, num_classes = number_classes)\n",
        "  y_testhot = to_categorical(y_test, num_classes = number_classes)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #     layer.trainable = True\n",
        "\n",
        "\n",
        "  model=Model_build_resnet()\n",
        "  model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "\n",
        "  # We will try to train the last stage of InceptionV3\n",
        "\n",
        "  filepath='/content/drive/My Drive/HRV-workplace/5-AnkleFx/Model/Ankle_fx_3sides_resnet.h5'\n",
        "\n",
        "  checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max',save_weights_only=True)\n",
        "  callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=patience, verbose=2),checkpoint]\n",
        "  # callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=patience, verbose=2)]\n",
        "\n",
        "\n",
        "  # Training the model for 10 epochs\n",
        "  # history = model.fit(x_train,y_trainHot, epochs=number_epoch, validation_data=(x_test,y_testhot) ,verbose=1 ,callbacks = callbacks_list)\n",
        "\n",
        "\n",
        "\n",
        "  history=model.fit([X_Frontal_train, X_Lateral_train,X_Oblique_train], y_trainHot,\n",
        "  validation_data=([X_Frontal_val, X_Lateral_val,X_Oblique_val], y_valhot),\n",
        "  epochs=number_epoch, batch_size=batch_size,callbacks = callbacks_list,verbose=1)\n",
        "\n",
        "\n",
        "  model=Model_build_resnet()\n",
        "  model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "\n",
        "  model.load_weights(filepath)\n",
        "\n",
        "\n",
        "\n",
        "  print('****** Train set evaluation .....\\n ')\n",
        "  # Evaluate model on train data\n",
        "  score = model.evaluate([X_Frontal_train, X_Lateral_train,X_Oblique_train],y_trainHot, verbose=0)\n",
        "  print('\\nKeras CNN - accuracy:', score[1], '\\n')\n",
        "  y_pred = model.predict([X_Frontal_train, X_Lateral_train,X_Oblique_train])\n",
        "  confusion_mtx=confusion_matrix(y_train, np.argmax(y_pred, axis=1))\n",
        "  print('\\n', sklearn.metrics.classification_report(np.where(y_trainHot > 0)[1], np.argmax(y_pred, axis=1), target_names=list(labels.values())), sep='') \n",
        "\n",
        "\n",
        "  # plt.show()\n",
        "  # plot_confusion_matrix(confusion_mtx, classes = list(labels.values()))\n",
        "  # plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  print('****** Val set evaluation .....\\n ')\n",
        "  # Evaluate model on test data\n",
        "  scores = model.evaluate([X_Frontal_val, X_Lateral_val,X_Oblique_val],y_valhot, verbose=0)\n",
        "  print('\\nKeras CNN - accuracy:', scores[1], '\\n')\n",
        "  y_pred = model.predict([X_Frontal_val, X_Lateral_val,X_Oblique_val])\n",
        "  confusion_mtx=confusion_matrix(y_val, np.argmax(y_pred, axis=1))\n",
        "  print('\\n', sklearn.metrics.classification_report(np.where(y_valhot > 0)[1], np.argmax(y_pred, axis=1), target_names=list(labels.values())), sep='') \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  print('****** Test set evaluation .....\\n ')\n",
        "  # Evaluate model on test data\n",
        "  x_test=[X_Frontal_test, X_Lateral_test,X_Oblique_test]\n",
        "  scores = model.evaluate([X_Frontal_test, X_Lateral_test,X_Oblique_test],y_testhot, verbose=0)\n",
        "  print('\\nKeras CNN - accuracy:', scores[1], '\\n')\n",
        "  y_pred = model.predict([X_Frontal_test, X_Lateral_test,X_Oblique_test])\n",
        "  confusion_mtx=confusion_matrix(y_test, np.argmax(y_pred, axis=1))\n",
        "  print('\\n', sklearn.metrics.classification_report(np.where(y_testhot > 0)[1], np.argmax(y_pred, axis=1), target_names=list(labels.values())), sep='') \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  print('****** Detail Test set evaluation .....\\n ')\n",
        "  from sklearn.metrics import precision_recall_fscore_support,roc_curve,auc\n",
        "  detail_result=precision_recall_fscore_support(np.where(y_testhot > 0)[1], np.argmax(y_pred, axis=1))\n",
        "  Specificity=confusion_mtx[1,1]/(confusion_mtx[1,1]+confusion_mtx[1,0])\n",
        "\n",
        "\n",
        "  fpr1, tpr1, thresholds =roc_curve(y_test, y_pred[:,1])\n",
        "  auc_result=auc(fpr1, tpr1)\n",
        "\n",
        "  print(\"Precision={}\\nRecall={}\\nSpecificity{}\\nFscore={}\".format(detail_result[0][0],detail_result[1][0],Specificity,detail_result[2][0]))\n",
        "  print('auc={}'.format(auc_result))\n",
        "\n",
        "\n",
        "  plot_learning_curve(history)\n",
        "\n",
        "  plt.show()\n",
        "  plot_confusion_matrix(confusion_mtx, classes = list(labels.values()))\n",
        "  plt.show()\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  model_score.append(scores[1] * 100)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #ROC\n",
        "\n",
        "    # Binarize the output\n",
        "  y_bin = label_binarize(y_testhot, classes=[0, 1])\n",
        "  n_classes = number_classes\n",
        "  lw=number_classes\n",
        "\n",
        "  y_score=model.predict(x_test)\n",
        "\n",
        "  fpr = dict()\n",
        "  tpr = dict()\n",
        "  roc_auc = dict()\n",
        "  for i in range(n_classes):\n",
        "      fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], y_score[:, i])\n",
        "      roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "  colors = cycle(['blue', 'red', 'green'])\n",
        "\n",
        "  print(roc_auc)\n",
        "  # for i, color in zip(range(n_classes), colors):\n",
        "  plt.plot(fpr[0], tpr[0], color='red', lw=lw,\n",
        "              label='Pre-trained Inceptiov-v3 (area = {:0.2f})'\n",
        "              ''.format(roc_auc[0]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "  plt.xlim([-0.01, 1.0])\n",
        "  plt.ylim([0.0, 1.05])\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  # plt.title('Receiver operating characteristic for multi-class data')\n",
        "  plt.legend(loc=\"lower right\")\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(model_score), np.std(model_score)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lG9e04tC_7G"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}